# 第4章 コンピューティングサービス

##4-1 AWSにおけるコンピューティングサービス
- コンピューティングサービスは、アプリケーションを稼働させるインフラストラクチャサービスで、システムアーキテクチャの中核を担う
  - EC2
    - 仮想サーバーを提供するコンピューティングサービス
    - 必要な数だけすぐにサービスを立てられる、IaaS型のサービス
    - Elastic Load Balancing(ELB)やAuto Scalingといったサービスと組み合わせると、負荷に応じて動的にサーバーの台数を変更するクラウドらしい使い方も可能
  - ECS
    - Dockerコンテナの実行環境を提供するサービス
    - AWSでDockerを利用するためには、EC2上にコンテナ管理用のソフトウェアの導入が必要であった
    - ECSはサービスとしてDocker環境を提供してくれるため、設定・構築の項目を減らすことが可能
  - Lambda
    - サーバーを用意しなくてもプログラムを実行できる環境を提供するサービス
    - サーバーレスアーキテクチャの中心と言えるサービスで、拡張性やコスト効率の面でメリットがある

##4-2 EC2
- Amazon Elastic Compute Cloud(EC2)は、インスタンスという単位でサーバーが管理され、簡単に新しいインスタンスを作ることができる
- オンプレミス環境に比べ、サーバー調達のリードタイムを非常に短くできる
- EC2を用いることでインフラリソースを柔軟に最適化することができる
- 事前の見積もりに時間をかけるのでなく、ビジネス的に価値を生む行為に注力できる
- 起動する際には、元となるイメージを選んでインスタンスを作成する、このイメージをAmazon Machine Image(AMI)と呼ぶ
- AMIにはAmazon Linux AMIやRed Hat Enterprise linuxなど、AWSが標準で提供しているものや、各ベンダーがサービスをプリインストールしたAMIがある

### EC2における性能の考え方
- EC2はインスタンスタイプという形で、インスタンスのスペックを選択することができる
- インスタンスタイプは「m5.large」といった形式で表記される、先頭の「m」はインスタンスファミリーを表し、何に最適化しているインスタンスタイプかを意味する
- インスタンスファミリーの後ろの数字は世代を表し、大きいものが最新となる
- 「large」の部分がインスタンスサイズを表し、大きいものほどスペックが高いインスタンスタイプになる
- Amazon EC2 インスタンスタイプ (AWS公式サイト)
  - https://aws.amazon.com/jp/ec2/instance-types
- インスタンスの性能を決める他の需要な要因として、ディスク機能であるEBS(Elastic Block Store)がある
- EBS最適化インスタンス
  - EC2では通常の通信で使用するネットワーク帯域と、EBSとのやり取りで利用する帯域を共有している
  - そのため、ディスクI/O、外部とのリクエストともに多く発生する場合、帯域が足りなくなることがあり、このようなときに利用できるオプション
  - このオプションを有効にすると、通常のネットワーク帯域とは別に、EBS用の帯域が確保される
  - ある程度大きめのインスタンスタイプでしか利用できないため、利用の際は、公式ドキュメントを確認

### EC2における費用の考え方
- EC2はインスタンスを使用した分だけ課金される従量課金型のサービス
- EC2のコストは下記により決まる
  - インスタンスがRunning状態だった時間
  - Running状態だったインスタンスのタイプ、AMI、起動リージョン
- インスタンスには、起動中(Running)、停止中(Stopped)、削除済み(Terminated)の3つの状態がある
- EC2では、起動しているインスタンスのみが課金対象になるため、一時的に停止中ステータスにしたインスタンスや削除したインスタンスは課金対象にならない
- 停止中のインスタンスでもEBSの費用はかかることに注意!!
- 起動しているインスタンスは、インスタンスタイプに応じて課金され、費用はリージョンやインスタンスのAMIによっても異なる

### スポットインスタンスとリザーブドインスタンス
- これまでの記述のEC2の価格は、オンデマンドインスタンスという通常の利用形態の場合のもの
- EC2には、これ以外に、スポットインスタンスとリザーブドインスタンスという利用オプションがある
  - スポットインスタンス
    - AWSが余らせているEC2リソースを入札形式で安く利用する方式
    - 利用リクエストが増え、余剰なリソースがなくなってしまうと、インスタンスが自動的に中断される
    - この制約を許容できる場合、例えば開発用の環境や機械学習のデータ学習のために一時的にスペックの大きいインスタンスを使いたいといった用途であれば、相性が良いオプションと言える
  - リザーブドインスタンス(RI)
    - 長期間の利用を約束することで割引を受けられるオプション
    - サービスをリリースしてからしばらく経ち、インスタンスタイプを固定できると判断できた時点でRIの購入を検討するとよい

### インスタンスの分類と用途
- 分類
  - 汎用
    - 一番利用の範囲が広くCPUとメモリのバランス型、M5やT3などが該当する
  - コンピューティング最適化
    - CPUの性能が高いもの、現状はC5などのC系統のみ
  - メモリ最適化
    - メモリ容量が大きいもの、R5やX1などの複数の系列があるが、一般的な利用でのメインはR系となる
  - 高速コンピューティング
    - GPUなどCPU以外の計算リソースが強化されている
    - かなり細分化されているが、画像処理用のP系と機械学習用のG系を押さえておくとよい
  - ストレージ最適化
    - ストレージ最適化もかなり細分化されているが、HDDを利用するD2とSSDを利用するI3を覚えておくこと

### Savings Plansとスケジュールされたリザーブドインスタンス
- Savings Plans
  - リザーブドインスタンスと比較して、より柔軟な形で割引を享受できるプラン
  - リザーブドインスタンスとの違いは、インスタンスの利用数ではなく、EC2インスタンスの利用額に対してコミットする点
  - Savings Plansには2種類ある
    - EC2 Instance Savings Plans
      - 従来のリザーブドインスタンスと同じようにリージョンやインスタンスファミリーを指定して購入
    - Compute Savings Plans
      - リージョンやインスタンスファミリーと関係なく、全てのEC2インスタンスを対象に単位時間あたりの利用料を指定して購入する
  - スケジュールされたリザーブドインスタンス
    - リザーブドインスタンスの買い方のパターン
    - 1年間のうちに毎日、毎週、毎月の一定時間のみ使うというパターンで、平日日中のみ使うという場合などに利用料を削減できる可能性がある
    - 対象のインスタンスはC3、C4、M4、およびR3
    - https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html

##4-3 ELB
- EC2の負荷が上がってきとしても、AWSでは多くのインスタンスタイプが用意されているため、ある程度まではインスタンスタイプを上げることで対応できる
- このような垂直にスペックを上げる対応をスケールアップと呼ぶ
- スケールアップには限度があり、また、単一インスタンスで運用を続けると、「そのインスタンスの停止＝サービス全体の停止」という状況になる
- 「ある特定の部分が止まると全体が止まってしまう」箇所のことを単一障害点(Single Point Of Failure、SPOF)と呼び、推奨されない
- いかに単一障害点を作らないかという視点は重要
- スケールアウト
  - 高負荷に耐えられる設計として、Webサーバーのレイヤーでベストプラクティスとなっているのが、EC2インスタンスを水平に並べるスケールアウト
  - EC2インスタンスを複数並べ、その前段にロードバランサーを配置してリクエストを各インスタンスに分散させる
  - ロードバランサーのマネージドサービスであるElastic Load Balancing(ELB)が推奨

### ELBの種類
- ELBには３タイプのロードバランサーがある
  - Classic Load Balancer(CLB)
    - L4/L7レイヤーでの負荷分散を行う
  - Application Load Balancer(ALB)
    - L7レイヤーでの負荷分散を行う、CLBより後に登場し、機能も豊富
  - Network Load Balancer(NLB)
    - L4レイヤーでの負荷分散を行う、HTTP(S)以外のプロトコル通信の負荷分散をしたいときに利用する

### ELBの特徴
- スケール
  - ELBを用いるメリットとして、ELBのスケーリングが挙げられる
  - ELBを用いた場合、負荷に応じて自動的にスケールする設計になっている
  - ただし、スケーリングが瞬時に完了するわけではないため、急激な負担増(スパイク)が予想できる場合は、事前にELBプレウォーミングの申請をしておく必要がある
- ヘルスチェック
  - ELBのもう一つの大きな利点
  - 設定された間隔で配下にあるEC2にリクエストを送り、各インスタンスが正常に動作しているか確認する機能
  - 異常なインスタンスを検知したときは自動的に切り離し、正常になったタイミングで改めてインスタンスをELBに紐付ける
  - ヘルスチェックの設定値
    - 対象のファイル
    - ヘルスチェックの間隔
    - 何回連続でリクエストが失敗したらインスタンスを切り離すか
    - 何回連続でリクエストが成功したらインスタンスを紐付けるか

### Auto Scaling
- システムの利用状況に応じて自動的にELBに紐付くインスタンスの台数を増減させる機能
- Auto Scalingでは以下の項目を設定することで、自動的なスケールアウト/スケールインを実現する
  - 最小のインスタンス数
  - 最大のインスタンス数
  - インスタンスの数を増やす条件と増やす数
  - インスタンスの数を減らす条件と減らす数
    - インスタンスの数を減らす際にどのインスタンスから削除するかといった設定も可能
- 繁忙期やピーク時間はインスタンスを増やし、閑散期や夜間のリクエストが少ないときにはそれなりのインスタンス数でサービスを運用するといったことが可能
- 耐障害性を上げることも可能

### スケーリングポリシー
- Auto Scaling のスケーリング方法は、大きく3つに分類できる
  - 動的なスケーリング(動的なスケーリングには、さらに3つのスケーリングポリシーがある)
    - 簡易スケーリング
      - CPU使用率が70％を超えたらというように、1つのメトリクスに対して1つの閾値を設定する
      - 現在は非推奨
    - ステップスケーリング
      - 1つのメトリクスに対して複数の閾値を設定する
      - 簡易スケーリングの上位互換
    - ターゲット追跡スケーリング
      - 1つのメトリクスに対して目標値を設定する
      - 今後は、このターゲット追跡スケジューリングが主流になる見通し
  - 予測スケーリング
  - スケジュールスケーリング

### スケールアウトの猶予期間・ウォームアップ・クールダウン
- パフォーマンスや信頼性を高めるために、Auto Scalingを使って需要に応じてインスタンス数を増減させる必要がある
- その際、インスタンスの起動中に新たなインスタンスが起動することを抑止する必要がある
- AWSにおける、そのための機構

### 猶予期間
- ヘルスチェックは、インスタンスの起動時間やインスタンス内のプロセスの起動時間があるために、すぐにそのインスタンスが利用可能になるわけではない
- その間にヘルスチェックでエラーが出続けると想定したスケーリング動作にならないため、一定時間ヘルスチェックをしないという猶予期間がある
- 画面コンソールから作成した場合の猶予期間はデフォルトで300秒(5分)、ただしCLIやSDKから作成した場合はデフォルトが0秒

### ウォームアップとクールダウン
- スケーリングクールダウン
  - Auto Scalingが発動した直後に、追加でインスタンスの増減がなされるのを防ぐための設定
  - クールダウンはインスタンスの増減のアクションの発動に対してのパラメータとなる
  - 現在ではクールダウンは主に簡易スケーリングのための設定であり、それ以外のスケーリングポリシーの場合は、デフォルトから調整しなくても済むようになっている
- スケーリングウォームアップ
  - ステップスケーリングにおいて差分でインスタンスを追加するために追加された機能
  - ステップスケーリングとターゲット追跡スケーリングポリシーに対応

### その他のAuto Scalingのオプション
- 代表的な2つがライフサイクルフックと終了ポリシー
- ライフサイクルフック
  - Auto Scalingグループによるインスタンスの起動時または削除時にインスタンスを一時停止してカスタムアクションを実行する機能
- 終了ポリシー
  - 負荷に応じてインスタンスを増やすことをスケールアウト
  - 負荷が下がってインスタンスを減らす場合はスケールイン
  - Auto Scalingで、スケールインの際にどのインスタンスを削除するのかを決めるのが終了ポリシー
  - デフォルトの終了ポリシーでは、インスタンスがアベイラビリティゾーンに均等に配分されるように削除する

### ELBとAuto Scalingを利用する際の設計ポイント
- サーバーをステートレスに、つまり状態を保持しないように設計すること
- AZをまたがってインスタンスを配置する設計にすること

##4-4 ECS
- Amazon Elastic Contaier Service(ECS)はDockerコンテナ環境を提供するサービス
- ECSが登場する前は、AWS上でDockerを導入するには、EC2上にソフトウェアを導入する必要があった

### ECSの特徴
- ECSに登場する概念
  - EC2インスタンス上で実行されるコンテナのことをTasKと呼び、EC2インスタンスのことはClusterと呼ぶ
  - 1つのCluster上で複数のTaskを実行することができる
  - Cluster上で動作するTaskの定義はTask Definitionで行う
  - 同じTaskを複数用意したい場面では、Serviceを用いる
  - Serviceでは、「Webサーバー用のTask DefinitionでTaskを4つ起動する」といった指定ができる
  - Serviceを利用することで、Taskの更新をブルーグリーンデプロイメントで行うこともできる
  - セキュリティ面の特徴としては、TaskごとにIAMロールを割り当てられることが挙げられる
    - 同じCluster上で起動するTaskごとに別のIAMロールを付与できるため、以下の権限管理も可能になる
      - Webサーバー用のTaskにはSQSへのSendMessage権限のみを付与する
      - 同じCluster上で動くバッチサーバーTaskには、SQSからのReceiveMessageとS3からのGetObjectの権限のみを付与する

### AWSにおけるその他のコンテナサービス
- ECS以外のコンテナ関連サービス
  - AWS Fragate
    - EC2を使わずにコンテナを動かすことができるサービス
    - Fragateを選択するとClusterの管理が必要なくなるため、ECSよりもさらにアプリケーション開発に集中できる
    - 各タスクに割り当てるCPUとメモリに応じて利用料が決まる
  - Amazon Elastic Contaier Service for Kubernetes(EKS)
    - コンテナ管理の自動化のためのオープンソースプラットフォーム
    - 従来はマスター用のEC2インスタンスを複数台用意し、管理する必要があったが、EKSはマスターをサービスとして提供するサービス
    - マスター用のEC2インスタンスを管理する必要がなくなった
  - Amazon Elastic Contaier Registry(ECR)
    - Dockerを用いる場合、そのコンテナイメージをレジストリで管理する必要がある
    - このレジストリをサービスとして提供するのがAmazon Elastic Contaier Registry(ECR)
    - レジストリの管理をECRに任せることができる

##4-5 Lambda
- サーバーをプロビジョニングしなくてもプログラムを実行できるコンピューティングサービスで、いわゆるサーバーレスアーキテクチャの中核
  - プロビジョニングってなんぞ？
  - 必要なリソースをあらかじめ用意しておくといった感じの意味
- Lambdaを用いるとソースコードの実行環境一式が提供されるため、利用者はソースコードだけ用意すれば、すぐにプログラムを実行できる
- リクエストの数に応じて自動的にスケールするので、処理に必要なサーバーの台数を考える必要はない
- サーバーを持たないため、パッチ当てなどの保守作業を行う必要がなく、利用者はインフラ管理の大部分をクラウド側に任せることができる

### Lambdaがサポートしているイベントとよく使われるアーキテクチャパターン
- Lambdaを利用するには、Lambda関数という単位で実行するプログラムとその実行トリガーとなるイベントを事前に定義する
- イベントが発生したタイミングでプログラムが実行される
- 指定できるイベントの一例
  - S3バケットにオブジェクトが追加されたとき/S3バケットからオブジェクトが削除されたとき
  - DynamoDBテーブルが更新されたとき
  - SNS通知が発行されたとき
  - SES(Simple Email Service)がメールを受信したとき
  - API GatewayへのHTTPSリクエストがあったとき
  - CloudWatch Eventsによって定義されたスケジューリング実行
- その他のサービスについては下記のドキュメント参照
  - https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-services.html

### Lambdaがサポートしているプログラミング言語
- Lambdaでは2020年12月時点で、下記のプログラミング言語をサポートしている
  - Node.js
  - Ruby
  - PowerShell
  - Python
  - C#
  - Java
  - Go
- 明確に向き不向きはないが、Pythonでは初回のLambda起動までの時間が短くなる傾向がある
- 逆にJavaでは、初回起動までの時間はかかるものの処理は早いという傾向がある
- Lambdaでは、利用する言語以外に下記の項目を設定する必要がある
  - 割り当てるメモリ量
  - タイムアウトまでの時間
  - Lambdaに割り当てるIAMロール
  - VPC内で実行するかVPCの外で実行するか

### Lambdaの課金体系
- 2020年12月時点のLambdaの利用料
  - Lambda関数の実行数:1,000,000件のリクエストにつき0.20USD
  - Lambda関数の実行時間:Lambda関数ごとに割り当てたメモリ量によって単位課金額が決まる
- Lambdaの課金体系は、リクエストの数と処理時間によって決まるリクエスト課金モデルになっている
- そのため、1時間に数回起動できればいいバッチや、どれくらいリクエストがくるか予想できないAPIを構築する際などに、コスト最適な構成にすることができる